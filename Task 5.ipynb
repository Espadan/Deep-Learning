{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.spatial import distance\n",
    "import time\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Device configuration\n",
    "#device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') \n",
    "#NVIDIA GT 630M - 2.1 <= 3.0 !!! cuDNN error: CUDNN_STATUS_ARCH_MISMATCH\n",
    "device = torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_ = \"data\"\n",
    "market_path_train = \"/Market-1501-v15.09.15/bounding_box_train\"\n",
    "market_path_test = \"/Market-1501-v15.09.15/bounding_box_test\"\n",
    "dist_market_path_train = \"/trainClasses\"\n",
    "dist_market_path_test = \"/testClasses\"\n",
    "dist_market_path_smallTest = \"/smallTest\"\n",
    "files_train = os.listdir(dir_ + market_path_train)\n",
    "files_test = os.listdir(dir_ + market_path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path, batch_size=1, shuffle=False):\n",
    "    data_path = dir_ + path\n",
    "    train_dataset = torchvision.datasets.ImageFolder(\n",
    "        root=data_path,\n",
    "        transform=torchvision.transforms.ToTensor()\n",
    "    )\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=0,\n",
    "        shuffle=shuffle\n",
    "    )\n",
    "    return train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = load_dataset(dist_market_path_train, batch_size=1000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = load_dataset(dist_market_path_smallTest, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inplace = 3 - кол-во входных каналов (RGB)\n",
    "\n",
    "class CNN_ReID(nn.Module):\n",
    "    def __init__(self, inplanes=3, planes1=8, planes2=16, planes3=32, stride=1):\n",
    "        super(CNN_ReID, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Sequential(nn.Conv2d(inplanes, planes1, kernel_size=3, stride=1, padding=1),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.MaxPool2d(kernel_size=2, stride=2)) \n",
    "        self.layer2 = nn.Sequential(nn.Conv2d(planes1, planes2, kernel_size=3, stride=1, padding=1), \n",
    "                                    nn.ReLU(),\n",
    "                                    nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer3 = nn.Sequential(nn.Conv2d(planes2, planes3, kernel_size=3, stride=1, padding=1), \n",
    "                                    nn.ReLU(),\n",
    "                                    nn.MaxPool2d(kernel_size=2, stride=2)) \n",
    "        #self.drop_out = nn.Dropout() \n",
    "        self.fc1 = nn.Linear(16 * 8 * planes3, 128) # 16*8*32 = 4096\n",
    "        self.fc2 = nn.Linear(128, 751) # 16*8*32 = 4096\n",
    "    def forward(self, x): \n",
    "        out = self.layer1(x) \n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        #out = self.drop_out(out)\n",
    "        out1 = self.fc1(out)\n",
    "        out2 = self.fc2(out1)\n",
    "        return out2, out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(num_epochs=10, weight_decay=0.001, momentum=0.9, learning_rate=0.01, name=\"model_0.ckpt\"):\n",
    "    model = CNN_ReID().to(device)\n",
    "    criterion = nn.CrossEntropyLoss() # CrossEntropyLoss() объединяет и SoftMax, и кросс-энтропийную функцию потерь\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay, momentum=momentum)\n",
    "\n",
    "    total_step = len(train_loader)\n",
    "    loss_list = []\n",
    "    acc_list = []\n",
    "\n",
    "    print(\"wd =\",weight_decay, \"momentum =\", momentum, \"lr = \", learning_rate)\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.to(device) \n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Прямой запуск\n",
    "            outputs2, outputs1 = model(images)\n",
    "            loss = criterion(outputs2, labels)\n",
    "            loss_list.append(loss.item())\n",
    "\n",
    "            # Обратное распространение и оптимизатор\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Отслеживание точности\n",
    "            total = labels.size(0)\n",
    "            _, predicted = torch.max(outputs2.data, 1)\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            acc_list.append(correct / total)\n",
    "\n",
    "            if (i + 1) % (total_step-1) == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.8f}%'\n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),\n",
    "                              (correct / total)))\n",
    "                \n",
    "    print(\"LOSS = \", loss.item(), \"wd =\", weight_decay, \"momentum =\", momentum, \"lr = \", learning_rate)\n",
    "    \n",
    "    # Save the model checkpoint\n",
    "    torch.save(model.state_dict(), name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wd = 0.001 momentum = 0.9 lr =  0.05\n",
      "Epoch [1/30], Step [12/13], Loss: 6.6158, Accuracy: 0.00100000%\n",
      "Epoch [2/30], Step [12/13], Loss: 6.5811, Accuracy: 0.00200000%\n",
      "Epoch [3/30], Step [12/13], Loss: 6.5302, Accuracy: 0.00600000%\n",
      "Epoch [4/30], Step [12/13], Loss: 6.4173, Accuracy: 0.00900000%\n",
      "Epoch [5/30], Step [12/13], Loss: 6.2056, Accuracy: 0.02200000%\n",
      "Epoch [6/30], Step [12/13], Loss: 5.8577, Accuracy: 0.03700000%\n",
      "Epoch [7/30], Step [12/13], Loss: 5.5557, Accuracy: 0.04600000%\n",
      "Epoch [8/30], Step [12/13], Loss: 5.1503, Accuracy: 0.08000000%\n",
      "Epoch [9/30], Step [12/13], Loss: 4.7737, Accuracy: 0.10700000%\n",
      "Epoch [10/30], Step [12/13], Loss: 4.5008, Accuracy: 0.12900000%\n",
      "Epoch [11/30], Step [12/13], Loss: 4.2545, Accuracy: 0.16000000%\n",
      "Epoch [12/30], Step [12/13], Loss: 4.2873, Accuracy: 0.19500000%\n",
      "Epoch [13/30], Step [12/13], Loss: 3.4205, Accuracy: 0.29800000%\n",
      "Epoch [14/30], Step [12/13], Loss: 2.9872, Accuracy: 0.36400000%\n",
      "Epoch [15/30], Step [12/13], Loss: 2.5919, Accuracy: 0.42800000%\n",
      "Epoch [16/30], Step [12/13], Loss: 2.2291, Accuracy: 0.49600000%\n",
      "Epoch [17/30], Step [12/13], Loss: 1.6704, Accuracy: 0.59900000%\n",
      "Epoch [18/30], Step [12/13], Loss: 1.5424, Accuracy: 0.63500000%\n",
      "Epoch [19/30], Step [12/13], Loss: 1.1150, Accuracy: 0.71400000%\n",
      "Epoch [20/30], Step [12/13], Loss: 0.7869, Accuracy: 0.78600000%\n",
      "Epoch [21/30], Step [12/13], Loss: 0.4913, Accuracy: 0.85400000%\n",
      "Epoch [22/30], Step [12/13], Loss: 0.4804, Accuracy: 0.85000000%\n",
      "Epoch [23/30], Step [12/13], Loss: 0.2729, Accuracy: 0.92200000%\n",
      "Epoch [24/30], Step [12/13], Loss: 0.2096, Accuracy: 0.94200000%\n",
      "Epoch [25/30], Step [12/13], Loss: 0.1509, Accuracy: 0.96200000%\n",
      "Epoch [26/30], Step [12/13], Loss: 0.1269, Accuracy: 0.96700000%\n",
      "Epoch [27/30], Step [12/13], Loss: 0.0944, Accuracy: 0.96800000%\n",
      "Epoch [28/30], Step [12/13], Loss: 0.0701, Accuracy: 0.98200000%\n",
      "Epoch [29/30], Step [12/13], Loss: 0.0625, Accuracy: 0.98600000%\n",
      "Epoch [30/30], Step [12/13], Loss: 0.0481, Accuracy: 0.98800000%\n",
      "LOSS =  0.039442870765924454 wd = 0.001 momentum = 0.9 lr =  0.05\n",
      "Time =  2588.6638350486755\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "trainModel(num_epochs=30, weight_decay=0.001, momentum=0.9, learning_rate=0.05, name=\"model_task5_0.ckpt\")\n",
    "print(\"Time = \", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wd = 0.001 momentum = 0.9 lr =  0.05\n",
      "Epoch [1/30], Step [12/13], Loss: 6.6177, Accuracy: 0.00300000%\n",
      "Epoch [2/30], Step [12/13], Loss: 6.6062, Accuracy: 0.00500000%\n",
      "Epoch [3/30], Step [12/13], Loss: 6.5671, Accuracy: 0.00500000%\n",
      "Epoch [4/30], Step [12/13], Loss: 6.5026, Accuracy: 0.00300000%\n",
      "Epoch [5/30], Step [12/13], Loss: 6.4812, Accuracy: 0.00500000%\n",
      "Epoch [6/30], Step [12/13], Loss: 6.4120, Accuracy: 0.00800000%\n",
      "Epoch [7/30], Step [12/13], Loss: 6.2185, Accuracy: 0.01800000%\n",
      "Epoch [8/30], Step [12/13], Loss: 5.8261, Accuracy: 0.03600000%\n",
      "Epoch [9/30], Step [12/13], Loss: 5.4581, Accuracy: 0.03900000%\n",
      "Epoch [10/30], Step [12/13], Loss: 5.1307, Accuracy: 0.07200000%\n",
      "Epoch [11/30], Step [12/13], Loss: 4.7584, Accuracy: 0.10700000%\n",
      "Epoch [12/30], Step [12/13], Loss: 4.2373, Accuracy: 0.15200000%\n",
      "Epoch [13/30], Step [12/13], Loss: 3.9584, Accuracy: 0.21200000%\n",
      "Epoch [14/30], Step [12/13], Loss: 3.3969, Accuracy: 0.30400000%\n",
      "Epoch [15/30], Step [12/13], Loss: 2.9130, Accuracy: 0.37500000%\n",
      "Epoch [16/30], Step [12/13], Loss: 2.5500, Accuracy: 0.43300000%\n",
      "Epoch [17/30], Step [12/13], Loss: 3.6222, Accuracy: 0.35100000%\n",
      "Epoch [18/30], Step [12/13], Loss: 2.0337, Accuracy: 0.55500000%\n",
      "Epoch [19/30], Step [12/13], Loss: 1.4880, Accuracy: 0.64300000%\n",
      "Epoch [20/30], Step [12/13], Loss: 3.9988, Accuracy: 0.34200000%\n",
      "Epoch [21/30], Step [12/13], Loss: 1.7821, Accuracy: 0.56800000%\n",
      "Epoch [22/30], Step [12/13], Loss: 1.1900, Accuracy: 0.69700000%\n",
      "Epoch [23/30], Step [12/13], Loss: 0.6579, Accuracy: 0.81400000%\n",
      "Epoch [24/30], Step [12/13], Loss: 0.4019, Accuracy: 0.88500000%\n",
      "Epoch [25/30], Step [12/13], Loss: 0.2117, Accuracy: 0.94300000%\n",
      "Epoch [26/30], Step [12/13], Loss: 0.1287, Accuracy: 0.95600000%\n",
      "Epoch [27/30], Step [12/13], Loss: 0.0713, Accuracy: 0.97600000%\n",
      "Epoch [28/30], Step [12/13], Loss: 0.0739, Accuracy: 0.97900000%\n",
      "Epoch [29/30], Step [12/13], Loss: 0.0663, Accuracy: 0.98000000%\n",
      "Epoch [30/30], Step [12/13], Loss: 0.0344, Accuracy: 0.99200000%\n",
      "LOSS =  0.035903796553611755 wd = 0.001 momentum = 0.9 lr =  0.05\n",
      "Time =  2576.429525613785\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "trainModel(num_epochs=30, weight_decay=0.001, momentum=0.9, learning_rate=0.05, name=\"model_task5_1.ckpt\")\n",
    "print(\"Time = \", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN_ReID(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc1): Linear(in_features=4096, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=751, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN_ReID()\n",
    "model.load_state_dict(torch.load(\"model_task5_0.ckpt\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1926"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs2, outputs1 = model(images)\n",
    "        test_features.append((str(labels.tolist()[0]), outputs1, images[0].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_distance_one(test_features, index):\n",
    "    list_dist = []\n",
    "    for i in range(len(test_features)):\n",
    "        if i != index:\n",
    "            dist_ = distance.cosine(test_features[index][1], test_features[i][1])\n",
    "            list_dist.append((test_features[i][0], dist_, test_features[i][2]))\n",
    "            list_dist.sort(key=lambda tup: tup[1])\n",
    "    result = (test_features[index][0], list_dist)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_distance_all(test_features):\n",
    "    result = []\n",
    "    for i in tqdm_notebook(range(len(test_features))):\n",
    "        distances_for_index = find_distance_one(test_features=test_features, index=i)\n",
    "        result.append(distances_for_index)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mAP(rangs, path_=\"data/testClasses/\"):\n",
    "    #{ { str_path, { {str_path_r_1, p_r_1}, {str_path_r_2, p_r_2}, .. {str_path_r_n, p_r_1} } }, ... }\n",
    " \n",
    "    len_rangs = len(rangs) #751\n",
    "    print(len_rangs)\n",
    "    sum_mAP = 0\n",
    "\n",
    "    for rang in rangs:\n",
    "        person = str(rang[0])\n",
    "        len_person = len(os.listdir(path_ + str(\"{:0>4s}\".format(person)) + '/')) - 1\n",
    "        sum_P = 0\n",
    "        sum_true = 0\n",
    "        i = 0\n",
    "        for rang_r in rang[1]:\n",
    "            i += 1\n",
    "            if rang_r[0] == person:\n",
    "                sum_true += 1\n",
    "                sum_P += sum_true/i\n",
    "            #print(\"Person: \", person, rang_r[0].split('_')[0], sum_true/i)\n",
    "        #print(\"Person:\", person, \"len_person:\", str(len_person), \"AP =\", sum_P/len_person)\n",
    "        sum_mAP += sum_P/len_person\n",
    "    return sum_mAP/len_rangs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features[58][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0063dd2fb1c42e0a69e53efd9bcdfd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1926), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rangs = find_distance_all(test_features=test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'49'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rangs[843][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.27224515098611113"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mAP(rangs=rangs, path_=\"data/smallTest/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
