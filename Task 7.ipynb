{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.spatial import distance\n",
    "import time\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "# Device configuration\n",
    "#device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') \n",
    "#NVIDIA GT 630M - 2.1 <= 3.0 !!! cuDNN error: CUDNN_STATUS_ARCH_MISMATCH\n",
    "device = torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_ = \"data\"\n",
    "market_path_train = \"/Market-1501-v15.09.15/bounding_box_train\"\n",
    "market_path_test = \"/Market-1501-v15.09.15/bounding_box_test\"\n",
    "market_path_query = \"/Market-1501-v15.09.15/query\"\n",
    "dist_market_path_train = \"/trainClasses\"\n",
    "dist_market_path_test = \"/testClasses\"\n",
    "dist_market_path_query = \"/queryClasses\"\n",
    "dist_market_path_smallTest = \"/smallTest\"\n",
    "dist_market_path_smallQuery = \"/smallQuery\"\n",
    "#files_train = os.listdir(dir_ + market_path_train)\n",
    "#files_test = os.listdir(dir_ + market_path_test)\n",
    "#files_query = os.listdir(dir_ + market_path_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_dataset(path, batch_size=1, shuffle=False):\n",
    "    data_path = dir_ + path\n",
    "    train_dataset = torchvision.datasets.ImageFolder(\n",
    "        root=data_path,\n",
    "        transform=transforms.Compose([\n",
    "            #torchvision.transforms.RandomHorizontalFlip(),\n",
    "            torchvision.transforms.ToTensor()\n",
    "        ])\n",
    "    )\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=0,\n",
    "        shuffle=shuffle\n",
    "    )\n",
    "    return train_loader\n",
    "\n",
    "def load_test_dataset(path, batch_size=1, shuffle=False):\n",
    "    data_path = dir_ + path\n",
    "    train_dataset = torchvision.datasets.ImageFolder(\n",
    "        root=data_path,\n",
    "        transform=torchvision.transforms.ToTensor()\n",
    "    )\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=0,\n",
    "        shuffle=shuffle\n",
    "    )\n",
    "    return train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_distance_one(object_with_features, test_features):\n",
    "    list_dist = []\n",
    "    for index in range(len(test_features)):\n",
    "        dist_ = distance.cosine(object_with_features[1], test_features[index][1])\n",
    "        list_dist.append((test_features[index][0], dist_, index))\n",
    "    list_dist.sort(key=lambda tup: tup[1])\n",
    "    result = (object_with_features[0], list_dist, object_with_features[2])\n",
    "    return result\n",
    "\n",
    "def find_distance_all(query_features, test_features):\n",
    "    result = []\n",
    "    for i in range(len(query_features)):\n",
    "        distances_for_object = find_distance_one(object_with_features=query_features[i],\n",
    "                                                 test_features=test_features)\n",
    "        result.append(distances_for_object)\n",
    "    return result\n",
    "\n",
    "def mAP(rangs, path_=\"data/testClasses/\"):\n",
    "    #{ { str_path, { {str_path_r_1, p_r_1}, {str_path_r_2, p_r_2}, .. {str_path_r_n, p_r_1} } }, ... }\n",
    "\n",
    "    len_rangs = len(rangs) #751\n",
    "    #print(len_rangs)\n",
    "    sum_mAP = 0\n",
    "\n",
    "    for rang in rangs:\n",
    "        person = str(rang[0])\n",
    "        len_person = len(os.listdir(path_ + str(\"{:0>4s}\".format(person)) + '/'))\n",
    "        sum_P = 0\n",
    "        sum_true = 0\n",
    "        i = 0\n",
    "        for rang_r in rang[1]:\n",
    "            i += 1\n",
    "            if rang_r[0] == person:\n",
    "                sum_true += 1\n",
    "                sum_P += sum_true/i\n",
    "            #print(\"Person: \", person, rang_r[0].split('_')[0], sum_true/i)\n",
    "        #print(\"Person:\", person, \"len_person:\", str(len_person), \"AP =\", sum_P/len_person)\n",
    "        sum_mAP += sum_P/len_person\n",
    "    return sum_mAP/len_rangs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, query_loader, path_):\n",
    "    test_features = []\n",
    "    print(\"Waiting output from test_loader...\")\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            outputs2, outputs1 = model(images)\n",
    "            test_features.append((str(labels.tolist()[0]), outputs1, images[0].numpy()))\n",
    "    len(test_features)\n",
    "\n",
    "    query_features = []\n",
    "    print(\"Waiting output from query_loader...\")\n",
    "    with torch.no_grad():\n",
    "        for images, labels in query_loader:\n",
    "            outputs2, outputs1 = model(images)\n",
    "            query_features.append((str(labels.tolist()[0]), outputs1, images[0].numpy()))\n",
    "    len(query_features)\n",
    "    \n",
    "    print(\"Waiting mAP...\")\n",
    "    rangs = find_distance_all(query_features=query_features, test_features=test_features)\n",
    "    return mAP(rangs=rangs, path_=path_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inplace = 3 - кол-во входных каналов (RGB)\n",
    "\n",
    "class CNN_ReID(nn.Module):\n",
    "    def __init__(self, inplanes=3, planes1=8, planes2=16, planes3=32, stride=1):\n",
    "        super(CNN_ReID, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Sequential(nn.Conv2d(inplanes, planes1, kernel_size=3, stride=1, padding=1),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.BatchNorm2d(planes1),\n",
    "                                    nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(nn.Conv2d(planes1, planes2, kernel_size=3, stride=1, padding=1),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.BatchNorm2d(planes2),\n",
    "                                    nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer3 = nn.Sequential(nn.Conv2d(planes2, planes3, kernel_size=3, stride=1, padding=1),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.BatchNorm2d(planes3),\n",
    "                                    nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        #self.drop_out = nn.Dropout() \n",
    "        self.fc1 = nn.Linear(16 * 8 * planes3, 128) # 16*8*32 = 4096\n",
    "        self.fc2 = nn.Linear(128, 751) # 16*8*32 = 4096\n",
    "    def forward(self, x): \n",
    "        out = self.layer1(x) \n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        #out = self.drop_out(out)\n",
    "        out1 = self.fc1(out)\n",
    "        out2 = self.fc2(out1)\n",
    "        return out2, out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(num_epochs=10, weight_decay=0.001, momentum=0.9, learning_rate=0.01, name=\"model_0.ckpt\",\n",
    "               train_loader=None, test_loader=None, query_loader=None):\n",
    "    model = CNN_ReID().to(device)\n",
    "    criterion = nn.CrossEntropyLoss() # CrossEntropyLoss() объединяет и SoftMax, и кросс-энтропийную функцию потерь\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay, momentum=momentum)\n",
    "\n",
    "    total_step = len(train_loader)\n",
    "    loss_list = []\n",
    "    acc_list = []\n",
    "\n",
    "    best_mAP = -1\n",
    "    \n",
    "    print(\"wd =\",weight_decay, \"momentum =\", momentum, \"lr = \", learning_rate)\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.to(device) \n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Прямой запуск\n",
    "            outputs2, outputs1 = model(images)\n",
    "            loss = criterion(outputs2, labels)\n",
    "            loss_list.append(loss.item())\n",
    "\n",
    "            # Обратное распространение и оптимизатор\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Отслеживание точности\n",
    "            total = labels.size(0)\n",
    "            _, predicted = torch.max(outputs2.data, 1)\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            acc_list.append(correct / total)\n",
    "            \n",
    "            if (i + 1) % (total_step-1) == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.8f}%'\n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),\n",
    "                              (correct / total)))\n",
    "                \n",
    "        new_mAP = test_model(model=model, test_loader=test_loader, query_loader=query_loader,\n",
    "                             path_=\"data/smallTest/\")\n",
    "        if (new_mAP >= best_mAP):\n",
    "            torch.save(model.state_dict(), name)\n",
    "            best_mAP = new_mAP\n",
    "            bestEpoch = epoch\n",
    "            print(\"bestModel was found! mAP: {:.4f}, epoch: {:d}\".format(best_mAP, bestEpoch))\n",
    "                \n",
    "                \n",
    "    print(\"LOSS =\", loss.item(), \"wd =\", weight_decay, \"momentum =\",\n",
    "          momentum, \"lr =\", learning_rate, \"best_mAP =\", best_mAP, \"bestEpoch =\", bestEpoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = load_train_dataset(dist_market_path_train, batch_size=1000, shuffle=True)\n",
    "\n",
    "test_loader = load_test_dataset(dist_market_path_smallTest, batch_size=1, shuffle=False)\n",
    "query_loader = load_test_dataset(dist_market_path_smallQuery, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with RandomHorizontalFlip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wd = 0.001 momentum = 0.9 lr =  0.05\n",
      "Epoch [1/1], Step [12/13], Loss: 6.2173, Accuracy: 0.02400000%\n",
      "Waiting output from test_loader...\n",
      "Waiting output from query_loader...\n",
      "Waiting mAP...\n",
      "bestModel was found! mAP: 0.1801, epoch: 0\n",
      "LOSS = 6.152338027954102 wd = 0.001 momentum = 0.9 lr = 0.05 best_mAP = 0.18008751047034063 bestEpoch = 0\n",
      "Time =  239.6184208393097\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "trainModel(num_epochs=, weight_decay=0.001, momentum=0.9, learning_rate=0.05, name=\"model_Test_MAP_2.ckpt\",\n",
    "          train_loader=train_loader, test_loader=test_loader, query_loader=query_loader)\n",
    "print(\"Time = \", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train with Self-Attention GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Self_Attn(nn.Module):\n",
    "    \"\"\" Self attention Layer\"\"\"\n",
    "    def __init__(self,in_dim):\n",
    "        super(Self_Attn,self).__init__()\n",
    "        self.chanel_in = in_dim\n",
    "        \n",
    "        self.query_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim//8 , kernel_size= 1)\n",
    "        self.key_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim//8 , kernel_size= 1)\n",
    "        self.value_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim , kernel_size= 1)\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "        self.softmax  = nn.Softmax(dim=-1) #\n",
    "    def forward(self,x):\n",
    "        \"\"\"\n",
    "            inputs :\n",
    "                x : input feature maps( B X C X W X H)\n",
    "            returns :\n",
    "                out : self attention value + input feature \n",
    "                attention: B X N X N (N is Width*Height)\n",
    "        \"\"\"\n",
    "        m_batchsize,C,width ,height = x.size()\n",
    "        proj_query  = self.query_conv(x).view(m_batchsize,-1,width*height).permute(0,2,1) # B X CX(N)\n",
    "        proj_key =  self.key_conv(x).view(m_batchsize,-1,width*height) # B X C x (*W*H)\n",
    "        energy =  torch.bmm(proj_query,proj_key) # transpose check\n",
    "        attention = self.softmax(energy) # BX (N) X (N) \n",
    "        proj_value = self.value_conv(x).view(m_batchsize,-1,width*height) # B X C X N\n",
    "\n",
    "        out = torch.bmm(proj_value,attention.permute(0,2,1) )\n",
    "        out = out.view(m_batchsize,C,width,height)\n",
    "        \n",
    "        out = self.gamma*out + x\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inplace = 3 - кол-во входных каналов (RGB)\n",
    "\n",
    "class CNN_ReID_SAGAN(nn.Module):\n",
    "    def __init__(self, inplanes=3, planes1=8, planes2=16, planes3=32, stride=1):\n",
    "        super(CNN_ReID_SAGAN, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Sequential(nn.Conv2d(inplanes, planes1, kernel_size=3, stride=1, padding=1),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.BatchNorm2d(planes1),\n",
    "                                    nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(nn.Conv2d(planes1, planes2, kernel_size=3, stride=1, padding=1),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.BatchNorm2d(planes2),\n",
    "                                    nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer3 = nn.Sequential(nn.Conv2d(planes2, planes3, kernel_size=3, stride=1, padding=1),\n",
    "                                    Self_Attn(planes3),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.BatchNorm2d(planes3),\n",
    "                                    nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        #self.drop_out = nn.Dropout() \n",
    "        self.fc1 = nn.Linear(16 * 8 * planes3, 128) # 16*8*32 = 4096\n",
    "        self.fc2 = nn.Linear(128, 751) # 16*8*32 = 4096\n",
    "    def forward(self, x): \n",
    "        out = self.layer1(x) \n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        #out = self.drop_out(out)\n",
    "        out1 = self.fc1(out)\n",
    "        out2 = self.fc2(out1)\n",
    "        return out2, out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel_SAGAN(num_epochs=10, weight_decay=0.001, momentum=0.9, learning_rate=0.01, name=\"model_0.ckpt\",\n",
    "               train_loader=None, test_loader=None, query_loader=None):\n",
    "    model = CNN_ReID_SAGAN().to(device)\n",
    "    criterion = nn.CrossEntropyLoss() # CrossEntropyLoss() объединяет и SoftMax, и кросс-энтропийную функцию потерь\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay, momentum=momentum)\n",
    "\n",
    "    total_step = len(train_loader)\n",
    "    loss_list = []\n",
    "    acc_list = []\n",
    "\n",
    "    best_mAP = -1\n",
    "    \n",
    "    print(\"wd =\",weight_decay, \"momentum =\", momentum, \"lr = \", learning_rate)\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.to(device) \n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Прямой запуск\n",
    "            outputs2, outputs1 = model(images)\n",
    "            loss = criterion(outputs2, labels)\n",
    "            loss_list.append(loss.item())\n",
    "\n",
    "            # Обратное распространение и оптимизатор\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Отслеживание точности\n",
    "            total = labels.size(0)\n",
    "            _, predicted = torch.max(outputs2.data, 1)\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            acc_list.append(correct / total)\n",
    "            \n",
    "            if (i + 1) % (total_step-1) == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.8f}%'\n",
    "                      .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),\n",
    "                              (correct / total)))\n",
    "                \n",
    "        new_mAP = test_model(model=model, test_loader=test_loader, query_loader=query_loader,\n",
    "                             path_=\"data/smallTest/\")\n",
    "        if (new_mAP >= best_mAP):\n",
    "            torch.save(model.state_dict(), name)\n",
    "            best_mAP = new_mAP\n",
    "            bestEpoch = epoch\n",
    "            print(\"bestModel was found! mAP: {:.4f}, epoch: {:d}\".format(best_mAP, bestEpoch))\n",
    "                \n",
    "                \n",
    "    print(\"LOSS =\", loss.item(), \"wd =\", weight_decay, \"momentum =\",\n",
    "          momentum, \"lr =\", learning_rate, \"best_mAP =\", best_mAP, \"bestEpoch =\", bestEpoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = load_train_dataset(dist_market_path_train, batch_size=540, shuffle=True)\n",
    "\n",
    "test_loader = load_test_dataset(dist_market_path_smallTest, batch_size=1, shuffle=False)\n",
    "query_loader = load_test_dataset(dist_market_path_smallQuery, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wd = 0.001 momentum = 0.9 lr =  0.05\n",
      "Epoch [1/1], Step [23/24], Loss: 5.5108, Accuracy: 0.08000000%\n",
      "Waiting output from test_loader...\n",
      "Waiting output from query_loader...\n",
      "Waiting mAP...\n",
      "bestModel was found! mAP: 0.2667, epoch: 0\n",
      "LOSS = 5.609541893005371 wd = 0.001 momentum = 0.9 lr = 0.05 best_mAP = 0.26667674870846636 bestEpoch = 0\n",
      "Time =  366.89804434776306\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "trainModel(num_epochs=50, weight_decay=0.001, momentum=0.9, learning_rate=0.05, name=\"model_Test_SAGAN_MAP_2.ckpt\",\n",
    "          train_loader=train_loader, test_loader=test_loader, query_loader=query_loader)\n",
    "print(\"Time = \", time.time() - start_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
